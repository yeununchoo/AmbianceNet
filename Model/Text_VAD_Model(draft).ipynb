{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "976819c8-ecc5-49cd-9dae-768ecfd29b5f",
   "metadata": {},
   "source": [
    "# Text VAD Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "943859f5-fdd3-4cf6-852e-f1741836e6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "# import tensorflow_datasets as tfds\n",
    "\n",
    "import itertools\n",
    "import string\n",
    "# import adjustText \n",
    "# import collections\n",
    "# import re\n",
    "import json\n",
    "\n",
    "# from tqdm.auto import tqdm\n",
    "\n",
    "save_figures = True\n",
    "data_path = \"../Data\"\n",
    "figure_path = \"../Figures\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa15f91-fdff-4787-a935-57f1021f4d69",
   "metadata": {},
   "source": [
    "## Load preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f73fdd99-cc7a-41c0-a389-2930ca3416f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_train_pd = pd.read_parquet(f\"{data_path}/reddit_train.parquet\")\n",
    "reddit_test_pd = pd.read_parquet(f\"{data_path}/reddit_test.parquet\")\n",
    "\n",
    "reddit_train_tokens = np.load(f\"{data_path}/reddit_train_tokens.npy\")\n",
    "reddit_test_tokens = np.load(f\"{data_path}/reddit_test_tokens.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b31a927a-fe8a-42a0-98d2-deaea4a49df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admiration</th>\n",
       "      <th>amusement</th>\n",
       "      <th>anger</th>\n",
       "      <th>annoyance</th>\n",
       "      <th>approval</th>\n",
       "      <th>caring</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>confusion</th>\n",
       "      <th>curiosity</th>\n",
       "      <th>desire</th>\n",
       "      <th>...</th>\n",
       "      <th>surprise</th>\n",
       "      <th>n_tags</th>\n",
       "      <th>valence_raw</th>\n",
       "      <th>arousal_raw</th>\n",
       "      <th>dominance_raw</th>\n",
       "      <th>valence</th>\n",
       "      <th>arousal</th>\n",
       "      <th>dominance</th>\n",
       "      <th>Weight_raw</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>b\"It's just wholesome content, from questionab...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.4690</td>\n",
       "      <td>0.1840</td>\n",
       "      <td>0.3570</td>\n",
       "      <td>0.059224</td>\n",
       "      <td>0.059224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>b'This is actually awesome.'</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.9690</td>\n",
       "      <td>0.5830</td>\n",
       "      <td>0.7260</td>\n",
       "      <td>0.004345</td>\n",
       "      <td>0.004345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>b\"People really spend more than $10 in an app ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.1535</td>\n",
       "      <td>0.4775</td>\n",
       "      <td>0.2205</td>\n",
       "      <td>0.028525</td>\n",
       "      <td>0.014263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   admiration  amusement  anger  annoyance  approval  caring  \\\n",
       "0       False      False  False      False     False   False   \n",
       "1        True      False  False      False     False   False   \n",
       "2       False      False  False      False     False   False   \n",
       "\n",
       "                                        comment_text  confusion  curiosity  \\\n",
       "0  b\"It's just wholesome content, from questionab...      False      False   \n",
       "1                       b'This is actually awesome.'      False      False   \n",
       "2  b\"People really spend more than $10 in an app ...       True      False   \n",
       "\n",
       "   desire  ...  surprise  n_tags  valence_raw  arousal_raw  dominance_raw  \\\n",
       "0   False  ...     False       1        0.469        0.184          0.357   \n",
       "1   False  ...     False       1        0.969        0.583          0.726   \n",
       "2   False  ...     False       2        0.307        0.955          0.441   \n",
       "\n",
       "   valence  arousal  dominance  Weight_raw    Weight  \n",
       "0   0.4690   0.1840     0.3570    0.059224  0.059224  \n",
       "1   0.9690   0.5830     0.7260    0.004345  0.004345  \n",
       "2   0.1535   0.4775     0.2205    0.028525  0.014263  \n",
       "\n",
       "[3 rows x 38 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2967 4781 3031 6206 1196 2273 4416 5224    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [5664 2955   62  397    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [4041 4505 5248 3590 5624 2820  198  251 2312 2757 3420  198   61 6051\n",
      "  2312 2757  811 5921  777 5631 4781 3031 4785    0    0    0    0    0\n",
      "     0    0]]\n"
     ]
    }
   ],
   "source": [
    "display(reddit_train_pd.head(n = 3))\n",
    "print(reddit_train_tokens[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa33999b-c44b-4137-9b2b-24570b91a669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admiration</th>\n",
       "      <th>amusement</th>\n",
       "      <th>anger</th>\n",
       "      <th>annoyance</th>\n",
       "      <th>approval</th>\n",
       "      <th>caring</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>confusion</th>\n",
       "      <th>curiosity</th>\n",
       "      <th>desire</th>\n",
       "      <th>...</th>\n",
       "      <th>surprise</th>\n",
       "      <th>n_tags</th>\n",
       "      <th>valence_raw</th>\n",
       "      <th>arousal_raw</th>\n",
       "      <th>dominance_raw</th>\n",
       "      <th>valence</th>\n",
       "      <th>arousal</th>\n",
       "      <th>dominance</th>\n",
       "      <th>Weight_raw</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>b\"You're right, thanks for pointing that out, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1.739</td>\n",
       "      <td>0.901</td>\n",
       "      <td>1.499</td>\n",
       "      <td>1.7390</td>\n",
       "      <td>0.901</td>\n",
       "      <td>1.4990</td>\n",
       "      <td>0.022136</td>\n",
       "      <td>0.022136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>b'Molon labe!!!'</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.4690</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.3570</td>\n",
       "      <td>0.059224</td>\n",
       "      <td>0.059224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>b'So this is what edging feels like'</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.2345</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.1785</td>\n",
       "      <td>0.059224</td>\n",
       "      <td>0.029612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   admiration  amusement  anger  annoyance  approval  caring  \\\n",
       "0       False      False  False      False      True   False   \n",
       "1       False      False  False      False     False   False   \n",
       "2       False      False  False      False     False   False   \n",
       "\n",
       "                                        comment_text  confusion  curiosity  \\\n",
       "0  b\"You're right, thanks for pointing that out, ...      False      False   \n",
       "1                                   b'Molon labe!!!'      False      False   \n",
       "2               b'So this is what edging feels like'      False      False   \n",
       "\n",
       "   desire  ...  surprise  n_tags  valence_raw  arousal_raw  dominance_raw  \\\n",
       "0   False  ...     False       1        1.739        0.901          1.499   \n",
       "1   False  ...     False       1        0.469        0.184          0.357   \n",
       "2   False  ...     False       2        0.469        0.184          0.357   \n",
       "\n",
       "   valence  arousal  dominance  Weight_raw    Weight  \n",
       "0   1.7390    0.901     1.4990    0.022136  0.022136  \n",
       "1   0.4690    0.184     0.3570    0.059224  0.059224  \n",
       "2   0.2345    0.092     0.1785    0.059224  0.029612  \n",
       "\n",
       "[3 rows x 38 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6349 4483 4707 5629 2211 4174 5631 3914 2757 6026 1792 2967 3769  847\n",
      "  3846    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [   1    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [5166 5664 2955 6183    1 2093 3230    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n"
     ]
    }
   ],
   "source": [
    "display(reddit_test_pd.head(n = 3))\n",
    "print(reddit_test_tokens[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ca4267-491a-4979-a8d2-10c0dd23742c",
   "metadata": {},
   "source": [
    "### Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13afef39-1b83-43dc-b7fd-6ea97f745379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6372\n",
      "[('*PAD*', 0), ('*UNK*', 1), ('a', 2), ('aa', 3), ('ab', 4), ('abandoned', 5), ('abhorrent', 6), ('ability', 7), ('able', 8), ('abnormal', 9), ('abortion', 10), ('abortions', 11), ('about', 12), ('above', 13), ('abroad', 14), ('absolute', 15), ('absolutely', 16), ('absurd', 17), ('abuse', 18), ('abused', 19), ('abusing', 20), ('abusive', 21), ('ac', 22), ('accent', 23), ('accept', 24), ('acceptable', 25), ('accepted', 26), ('accepting', 27), ('access', 28), ('accident', 29)]\n"
     ]
    }
   ],
   "source": [
    "with open(f\"{data_path}/token_dictionary.json\", \"r\") as readfile:\n",
    "    word_to_index_dict = json.load(readfile)\n",
    "\n",
    "print(len(word_to_index_dict))\n",
    "print(list(word_to_index_dict.items())[0:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a20cc4a-b5ee-4d0c-acf0-a299bb61d8ae",
   "metadata": {},
   "source": [
    "### VAD mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cad36949-af97-4f41-8f78-ca236919739b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admiration</th>\n",
       "      <th>amusement</th>\n",
       "      <th>anger</th>\n",
       "      <th>annoyance</th>\n",
       "      <th>approval</th>\n",
       "      <th>caring</th>\n",
       "      <th>confusion</th>\n",
       "      <th>curiosity</th>\n",
       "      <th>desire</th>\n",
       "      <th>disappointment</th>\n",
       "      <th>...</th>\n",
       "      <th>love</th>\n",
       "      <th>nervousness</th>\n",
       "      <th>neutral</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pride</th>\n",
       "      <th>realization</th>\n",
       "      <th>relief</th>\n",
       "      <th>remorse</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>valence</th>\n",
       "      <td>0.969</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.115</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arousal</th>\n",
       "      <td>0.583</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dominance</th>\n",
       "      <td>0.726</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.336</td>\n",
       "      <td>...</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           admiration  amusement  anger  annoyance  approval  caring  \\\n",
       "valence         0.969      0.929  0.167      0.167     0.854   0.635   \n",
       "arousal         0.583      0.837  0.865      0.718     0.460   0.469   \n",
       "dominance       0.726      0.803  0.657      0.342     0.889   0.500   \n",
       "\n",
       "           confusion  curiosity  desire  disappointment  ...   love  \\\n",
       "valence        0.255      0.750   0.896           0.115  ...  1.000   \n",
       "arousal        0.667      0.755   0.692           0.490  ...  0.519   \n",
       "dominance      0.277      0.463   0.647           0.336  ...  0.673   \n",
       "\n",
       "           nervousness  neutral  optimism  pride  realization  relief  \\\n",
       "valence          0.163    0.469     0.949  0.729        0.554   0.844   \n",
       "arousal          0.915    0.184     0.565  0.634        0.510   0.278   \n",
       "dominance        0.241    0.357     0.814  0.848        0.836   0.481   \n",
       "\n",
       "           remorse  sadness  surprise  \n",
       "valence      0.103    0.052     0.875  \n",
       "arousal      0.673    0.288     0.875  \n",
       "dominance    0.377    0.164     0.562  \n",
       "\n",
       "[3 rows x 28 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "emotion_vad_mapping = np.array([\n",
    "    [0.969,0.583,0.726],\n",
    "    [0.929,0.837,0.803],\n",
    "    [0.167,0.865,0.657],\n",
    "    [0.167,0.718,0.342],\n",
    "    [0.854,0.46,0.889],\n",
    "    [0.635,0.469,0.5],\n",
    "    [0.255,0.667,0.277],\n",
    "    [0.75,0.755,0.463],\n",
    "    [0.896,0.692,0.647],\n",
    "    [0.115,0.49,0.336],\n",
    "    [0.085,0.551,0.367],\n",
    "    [0.052,0.775,0.317],\n",
    "    [0.143,0.685,0.226],\n",
    "    [0.896,0.684,0.731],\n",
    "    [0.073,0.84,0.293],\n",
    "    [0.885,0.441,0.61],\n",
    "    [0.07,0.64,0.474],\n",
    "    [0.98,0.824,0.794],\n",
    "    [1,0.519,0.673],\n",
    "    [0.163,0.915,0.241],\n",
    "    [0.469,0.184,0.357],\n",
    "    [0.949,0.565,0.814],\n",
    "    [0.729,0.634,0.848],\n",
    "    [0.554,0.51,0.836],\n",
    "    [0.844,0.278,0.481],\n",
    "    [0.103,0.673,0.377],\n",
    "    [0.052,0.288,0.164],\n",
    "    [0.875,0.875,0.562]])\n",
    "\n",
    "emotion_columns = [\n",
    "    \"admiration\", \"amusement\", \"anger\", \"annoyance\", \"approval\", \n",
    "    \"caring\", \"confusion\", \"curiosity\", \"desire\", \"disappointment\",\n",
    "    \"disapproval\", \"disgust\", \"embarrassment\", \"excitement\", \"fear\",\n",
    "    \"gratitude\", \"grief\", \"joy\", \"love\", \"nervousness\", \n",
    "    \"neutral\", \"optimism\", \"pride\", \"realization\", \"relief\", \n",
    "    \"remorse\", \"sadness\",\"surprise\"]\n",
    "\n",
    "emotion_vad_mapping_pd = pd.DataFrame(columns = [\"valence\", \"arousal\", \"dominance\"], \n",
    "                                      data = emotion_vad_mapping, \n",
    "                                      index = emotion_columns)\n",
    "display(emotion_vad_mapping_pd.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4210fd-fa82-46e4-87d4-bd485d3966a4",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9462eb83-d3c4-4a72-80cc-8cf1e2209b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Text_VAD(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, window_size):\n",
    "        super(Text_VAD, self).__init__()\n",
    "        self.vocab_size = vocab_size # The size of the English vocab\n",
    "        self.window_size = window_size # The English window size\n",
    "\n",
    "        # TODO:\n",
    "        # 1) Define any hyperparameters\n",
    "\n",
    "        # Define batch size and optimizer/learning rate\n",
    "        self.batch_size = 128 # You probably should change this\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate = 0.01) ## what should the learning rate be????\n",
    "        self.embedding_size = 64 # You should change this too\n",
    "\n",
    "        # 2) Define embeddings, encoder, decoder, and feed forward layers\n",
    "        \n",
    "        initializer = tf.keras.initializers.TruncatedNormal(mean = 0.0, stddev = 0.01)\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(self.vocab_size, \n",
    "                                                   self.embedding_size, \n",
    "                                                   embeddings_initializer = initializer,\n",
    "                                                   name = \"french_embedding\")\n",
    "        \n",
    "        # Convolution? LSTM? Bi-directional LSTM Dense?\n",
    "        # How many layers?\n",
    "        self.next_layers_1 = None \n",
    "        self.next_layers_2 = None \n",
    "        self.next_layers_3 = None \n",
    "\n",
    "    @tf.function\n",
    "    def call(self, text_input):\n",
    "        \"\"\"\n",
    "        :param text_input: batched tokenized words of the reddit comments, [batch_size x window_size]\n",
    "        :return VAD_coordinates: The 3d VAD coordinates as a tensor, [batch_size x 3]\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO:\n",
    "        # 1) Pass your French sentence embeddings to your encoder\n",
    "        # 2) Pass your English sentence embeddings, and final state of your encoder, to your decoder\n",
    "        # 3) Apply dense layer(s) to the decoder out to generate probabilities\n",
    "        \n",
    "        embedding_layer = self.embedding(text_input)\n",
    "        \n",
    "        ## do something here\n",
    "        \n",
    "        VAD_coordinates = None\n",
    "        \n",
    "        # The final result should look like this\n",
    "        # VAD_coordinates = \n",
    "        #     [[v_1, a_1, d_1],\n",
    "        #      [v_2, a_2, d_2],\n",
    "        #      ...\n",
    "        #      [v_batch, a_batch, d_batch]]\n",
    "        \n",
    "        return VAD_coordinates\n",
    "\n",
    "\n",
    "    def loss_function(self, VAD_true, VAD_pred, sample_weights):\n",
    "        \"\"\"\n",
    "        Calculates the Euclidean distance between the true VAD coordinates and the predicted coordinates.\n",
    "\n",
    "        :param VAD_true: float tensor, [batch_size x 3]\n",
    "        :param VAD_pred: float tensor, [batch_size x 3]\n",
    "        :param sample_weights: float tensor, [batch_size x 1]\n",
    "\n",
    "        :return: the loss of the model as a tensor\n",
    "        \"\"\"\n",
    "        \n",
    "        ## Return the weighted average of euclidean distances\n",
    "        ## loss = (weight_1*distance_1 + weight_2*distance_2 + ... + weight_n*distance_n)/(n_batch)\n",
    "\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11f032f-fa95-4305-bf19-6c42d93fad94",
   "metadata": {},
   "source": [
    "## Customized train, test, accuracy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eeaf9fa5-e46b-4d23-8f81-2f1b880bcc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, text_input, VAD_true, sample_weights):\n",
    "    \"\"\"\n",
    "    Runs through one epoch - all training examples.\n",
    "\n",
    "    :param model: the initialized model to use for forward and backward pass\n",
    "    :param text_input: batched tokenized words of the reddit comments, [batch_size x window_size]\n",
    "    :param VAD_true: float tensor, [batch_size x 3]\n",
    "    :param sample_weights: float tensor, [batch_size x 1]\n",
    "    \n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    input_size = len(text_input)\n",
    "    batch_size = model.batch_size\n",
    "    \n",
    "    # drop the rest of the data that do not fit in batches\n",
    "    input_size = input_size - (input_size%batch_size)\n",
    "    \n",
    "    # shuffle\n",
    "    shuffled_index = tf.random.shuffle(tf.range(input_size))\n",
    "    shuffled_text_input  = tf.gather(text_input, shuffled_index)\n",
    "    shuffled_VAD_true = tf.gather(VAD_true, shuffled_index)\n",
    "    \n",
    "    for train_index in range(0, input_size, batch_size): \n",
    "        batch_text_input = shuffled_text_input[train_index:(train_index + batch_size)]\n",
    "        batch_VAD_true   = shuffled_VAD_true[train_index:(train_index + batch_size)]\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # get the loss for this batch\n",
    "            batch_VAD_pred = model(batch_text_input, \n",
    "                                   batch_VAD_true)\n",
    "            batch_loss = model.loss_function(batch_VAD_true, \n",
    "                                             batch_VAD_pred, \n",
    "                                             sample_weights)\n",
    "            \n",
    "        gradients = tape.gradient(batch_loss, model.trainable_variables)\n",
    "        \n",
    "        model.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        \n",
    "        if train_index%(batch_size*200) == 0:\n",
    "            print(f\"training on batch {train_index}, \"\n",
    "                  f\"progress {100*(train_index + batch_size)/(input_size):2.1f}%, \"\n",
    "                  f\"loss {batch_loss:.4f}\")\n",
    "    \n",
    "    print(f\"training over\\n\"\n",
    "          f\"last batch {train_index}, \"\n",
    "          f\"progress {100*(train_index + batch_size)/(input_size):2.1f}%, \"\n",
    "          f\"loss {batch_loss:.4f}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d364bc0-2aff-4392-a1a3-9227aeabf458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, text_input, VAD_true):\n",
    "    \"\"\"\n",
    "    Runs through one epoch - all training examples.\n",
    "\n",
    "    :param model: the initialized model to use for forward and backward pass\n",
    "    :param text_input: batched tokenized words of the reddit comments, [batch_size x window_size]\n",
    "    :param VAD_true: float tensor, [batch_size x 3]\n",
    "    \n",
    "    :return: Loss\n",
    "    \"\"\"\n",
    "    \n",
    "    ## Do something similar to train\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30bcedc9-ec49-4b96-9f87-dd6fbea80214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, text_input, onehot_emotion_labels, emotion_vad_mapping_pd):\n",
    "    \"\"\"\n",
    "    Runs through one epoch - all training examples.\n",
    "\n",
    "    Predict the VAD coordinate for the input text\n",
    "    Find the closest emotion label on the VAD space\n",
    "    See if the model has chosen the correct emotion label\n",
    "\n",
    "    :param model: the initialized model to use for forward and backward pass\n",
    "    :param text_input: batched tokenized words of the reddit comments, [batch_size x window_size]\n",
    "    :param onehot_emotion_labels: boolean tensor, [batch_size x 28]\n",
    "    \n",
    "    :return: average accuracy\n",
    "    \"\"\"\n",
    "    \n",
    "    ## return the average accuracy\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd26e75-d891-459f-90d6-46d5e1e36574",
   "metadata": {},
   "source": [
    "## Train/test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5694f7f4-7bd5-44e5-b25b-c1ed509b3213",
   "metadata": {},
   "source": [
    "### Prepare the input tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa269fca-9f56-4c6c-b4dd-8b59340a12d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43410, 30)\n",
      "\n",
      "(5427, 30)\n",
      "\n",
      "(43410, 3)\n",
      "\n",
      "(5427, 3)\n"
     ]
    }
   ],
   "source": [
    "text_input_train = reddit_train_tokens\n",
    "text_input_test = reddit_test_tokens\n",
    "\n",
    "VAD_true_train = reddit_train_pd[[\"valence\", \"arousal\", \"dominance\"]].to_numpy()\n",
    "VAD_true_test = reddit_test_pd[[\"valence\", \"arousal\", \"dominance\"]].to_numpy()\n",
    "\n",
    "print(text_input_train.shape)\n",
    "# print(text_input_train[0:3])\n",
    "print(\"\")\n",
    "\n",
    "print(text_input_test.shape)\n",
    "# print(text_input_test[0:3])\n",
    "print(\"\")\n",
    "\n",
    "print(VAD_true_train.shape)\n",
    "# print(VAD_true_train[0:3])\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(VAD_true_test.shape)\n",
    "# print(VAD_true_test[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6fb0c75-294a-4561-bda1-116afe708ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43410,)\n",
      "(5427,)\n"
     ]
    }
   ],
   "source": [
    "sample_weights_train = reddit_train_pd[\"Weight\"].to_numpy()\n",
    "print(sample_weights_train.shape)\n",
    "\n",
    "sample_weights_test = reddit_test_pd[\"Weight\"].to_numpy()\n",
    "print(sample_weights_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "557ceb9e-5638-43d8-b602-611483489fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43410, 28)\n",
      "\n",
      "(5427, 28)\n"
     ]
    }
   ],
   "source": [
    "onehot_emotion_labels_train = reddit_train_pd[emotion_columns].to_numpy()\n",
    "print(onehot_emotion_labels_train.shape)\n",
    "print(\"\")\n",
    "\n",
    "onehot_emotion_labels_test = reddit_test_pd[emotion_columns].to_numpy()\n",
    "print(onehot_emotion_labels_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871b48c1-8e59-4718-8308-f4b9fc514b89",
   "metadata": {},
   "source": [
    "### Initialize the model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9598cb9b-0ecf-4e79-8720-51d098e57847",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 3 ## how many epochs are needed???\n",
    "vocab_size = len(word_to_index_dict)\n",
    "window_size = 30\n",
    "\n",
    "model = Text_VAD(vocab_size, 30)\n",
    "\n",
    "# for each_epoch in range(n_epochs):\n",
    "#     train(model, text_input_train, VAD_true_train, sample_weights_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "704ec7c5-fe73-49dc-ad8f-5584e17b57ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loss = test(model, text_input_test, VAD_true_test)\n",
    "# test_accuracy = accuracy(model, text_input_test, onehot_emotion_labels_test, emotion_vad_mapping_pd)\n",
    "# print(f\"test loss: {test_loss}\")\n",
    "# print(f\"test accuracy: {100*test_accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c098b586-21c8-4f99-9b25-3522f797040b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
